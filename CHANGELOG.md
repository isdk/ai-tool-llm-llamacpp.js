# Changelog

All notable changes to this project will be documented in this file. See [commit-and-tag-version](https://github.com/absolute-version/commit-and-tag-version) for commit guidelines.

## [0.5.9](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.8...v0.5.9) (2025-09-23)

## [0.5.8](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.7...v0.5.8) (2025-09-21)


### Features

* add perplexity into result if any completion_probabilities ([5396c80](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/5396c8012aea162a006ae95735df11e66edaf3d0))


### Bug Fixes

* should pass options too ([80d20b7](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/80d20b7fa3518bb2323c508c2b9f6dbc6eb22671))

## [0.5.7](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.6...v0.5.7) (2025-04-04)

## [0.5.6](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.5...v0.5.6) (2025-03-22)

## [0.5.5](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.4...v0.5.5) (2025-03-17)

## [0.5.4](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.3...v0.5.4) (2025-03-17)

## [0.5.3](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.2...v0.5.3) (2025-03-16)

## [0.5.2](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.1...v0.5.2) (2025-03-16)

## [0.5.1](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.5.0...v0.5.1) (2025-03-16)

## [0.5.0](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.4.2...v0.5.0) (2025-03-16)


### ⚠ BREAKING CHANGES

* add options to getModelInfo

### Features

* pass shouldThink option ([66ad5ad](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/66ad5ad432ff1dec3d3da01005965f9159916f99))


### Bug Fixes

* loadModel raise error should display model ([a9acc54](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/a9acc549f8d180df405235fb2e08253be34f19b4))
* should loadModel without currentModel ([bd7e166](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/bd7e166c61d200f558dd03113efbf20e54b25660))
* should return the model id correctly ([1ff6d37](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/1ff6d375e2e4f3559b66ecc0198b670801360a90))


### Refactor

* add options to getModelInfo ([3f00df7](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/3f00df749837b4a9452f6e30f053c39c794fdd18))
* extract _tokenize from tokenize ([2d90966](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/2d90966dfebe54415429ec5e53b803585d6cc6ab))
* extract fetch from func ([9066d49](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/9066d491538859f83f2aee46bd128650748c7769))

## [0.4.2](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.4.1...v0.4.2) (2024-12-18)

## [0.4.1](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.4.0...v0.4.1) (2024-12-17)

## [0.4.0](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.14...v0.4.0) (2024-12-15)


### ⚠ BREAKING CHANGES

* add new llamacpp protocol supports

### Features

* add tokenize and countTokens ([c7de3d2](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/c7de3d294587fa6d2837babbd0e4eed1d2ca0465))


### Bug Fixes

* add new llamacpp protocol supports ([4a295ab](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/4a295abe49bf283a8ebce2bd5c5b428e7aeec859))
* for new llama-server /props spec ([9bd500c](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/9bd500cbc57f5f013d0fa5f67df260298f13c3d3))


### Refactor

* add AIChatMessageParam[] supports ([b5e6b88](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/b5e6b8874ef97a0fe766a3a24ea99b175014f6a6))
* update options ([4cd8088](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/4cd8088f8689fc990ef2be6724cce6bbfee7c2df))

## [0.3.14](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.13...v0.3.14) (2024-10-04)

## [0.3.13](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.12...v0.3.13) (2024-09-30)

## [0.3.12](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.11...v0.3.12) (2024-09-25)


### Bug Fixes

* forget to pass model ([edd1ceb](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/edd1ceb91a1f9822c57d5ee3f3ffd8be5fd667de))


### Refactor

* add default model supports ([e3f6ebe](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/e3f6ebe5837fed6d620d192f65e20fcce33196a5))

## [0.3.11](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.10...v0.3.11) (2024-09-17)

## [0.3.10](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.9...v0.3.10) (2024-09-16)

## [0.3.9](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.8...v0.3.9) (2024-09-02)

## [0.3.8](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.7...v0.3.8) (2024-09-02)

## [0.3.7](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.6...v0.3.7) (2024-09-01)

## [0.3.6](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.5...v0.3.6) (2024-08-31)

## [0.3.5](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.4...v0.3.5) (2024-08-28)

## [0.3.4](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.3...v0.3.4) (2024-08-25)

## [0.3.3](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.2...v0.3.3) (2024-08-24)

## [0.3.2](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.1...v0.3.2) (2024-08-24)

## [0.3.1](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.3.0...v0.3.1) (2024-08-24)

## [0.3.0](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.2.0...v0.3.0) (2024-08-23)


### ⚠ BREAKING CHANGES

* add loadModel as base class

### Refactor

* add loadModel as base class ([bddcb35](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/bddcb350cde2314c95df2454df8e6e5e2a38d96d))

## [0.2.0](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.1.0...v0.2.0) (2024-08-18)


### ⚠ BREAKING CHANGES

* sync to llama.cpp

### Refactor

* sync to llama.cpp ([93d3582](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/93d35820584e194d5f0d1f510bbd9e1fb303d907))

## [0.1.0](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.12...v0.1.0) (2024-08-16)


### ⚠ BREAKING CHANGES

* the max_tokens can work on the new llama.cpp

### Features

* the max_tokens can work on the new llama.cpp ([2759313](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/2759313967904252280491cfb03ef5fb58f19ce1))


### Bug Fixes

* should convert the options in the stream ([fc98f39](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/fc98f39e3b115ecb3b202be85a03fb23642cba74))

## [0.0.12](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.11...v0.0.12) (2024-08-14)

## [0.0.11](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.10...v0.0.11) (2024-08-11)


### Features

* add makeToolFuncCancelable ability ([0839bda](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/0839bdad8b86cb69bc20c1f6ac8c7c8d05d2f137))
* add mutiltask aborter supports ([bfe7eb9](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/bfe7eb92364c46c6a1356c53edaa03b3cf504c26))


### Refactor

* follow the ai-tool update CancelableAbility ([4375b77](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/4375b779a687ce47cc4114816e30dcf3e9412caa))

## [0.0.10](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.9...v0.0.10) (2024-07-08)

## [0.0.9](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.8...v0.0.9) (2024-06-21)

## [0.0.8](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.7...v0.0.8) (2024-06-13)


### Bug Fixes

* should allow stop_words to be a string ([d5d88f7](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/d5d88f724f83e505c778b2363cb62eeee3c2ceef))

## [0.0.7](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.6...v0.0.7) (2024-06-11)

## [0.0.6](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.5...v0.0.6) (2024-06-10)

## [0.0.5](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.4...v0.0.5) (2024-06-10)

## [0.0.4](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.3...v0.0.4) (2024-06-09)

## [0.0.3](https://github.com/isdk/ai-tool-llm-llamacpp.js/compare/v0.0.2...v0.0.3) (2024-06-09)


### Features

* expose the chatTemplateId to result for better debug ([d3b305c](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/d3b305c35cb3c708a6eebf74554559e930a3ef35))


### Bug Fixes

* pass additional optins to streamable result ([736756c](https://github.com/isdk/ai-tool-llm-llamacpp.js/commit/736756c4bb559b821df4e8d8b3cf28140a1a18c5))

## 0.0.2 (2024-06-08)
